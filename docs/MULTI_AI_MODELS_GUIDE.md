# å¤šAIæ¨¡å‹æ”¯æŒç³»çµ±ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

CardStrategy çš„å¤šAIæ¨¡å‹æ”¯æŒç³»çµ±æä¾›äº†å¼·å¤§çš„AIåŠŸèƒ½ï¼Œæ”¯æŒå¤šå€‹ä¸»æµAIæä¾›å•†ï¼ˆOpenAIã€Claudeã€Geminiã€Azureç­‰ï¼‰ï¼Œä¸¦æä¾›æ™ºèƒ½çš„æ¨¡å‹é¸æ“‡ã€è² è¼‰å¹³è¡¡å’Œæˆæœ¬å„ªåŒ–åŠŸèƒ½ã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### âœ… æ”¯æŒçš„AIæä¾›å•†

- **OpenAI** - GPT-4, GPT-3.5-turbo
- **Anthropic Claude** - Claude-3, Claude-2
- **Google Gemini** - Gemini Pro, Gemini Vision
- **Microsoft Azure** - Azure OpenAI
- **Cohere** - Command, Command Light
- **Hugging Face** - é–‹æºæ¨¡å‹
- **æœ¬åœ°æ¨¡å‹** - Llama-2, Mistral
- **è‡ªå®šç¾©æ¨¡å‹** - æ”¯æŒæ·»åŠ è‡ªå®šç¾©AIæä¾›å•†

### âœ… æ™ºèƒ½åŠŸèƒ½

- **è‡ªå‹•æ¨¡å‹é¸æ“‡** - æ ¹æ“šä»»å‹™é¡å‹è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹
- **è² è¼‰å¹³è¡¡** - å¤šç¨®è² è¼‰å¹³è¡¡ç­–ç•¥ï¼ˆå„ªå…ˆç´šã€æˆæœ¬å„ªåŒ–ã€æ€§èƒ½å„ªåŒ–ã€è¼ªè©¢ï¼‰
- **æ•…éšœè½‰ç§»** - è‡ªå‹•å‚™ç”¨æä¾›å•†åˆ‡æ›
- **æˆæœ¬å„ªåŒ–** - æ™ºèƒ½æˆæœ¬æ§åˆ¶å’Œå„ªåŒ–
- **æ€§èƒ½ç›£æ§** - å¯¦æ™‚æ€§èƒ½æŒ‡æ¨™è¿½è¹¤
- **æ‰¹é‡è™•ç†** - æ”¯æŒæ‰¹é‡AIè«‹æ±‚è™•ç†

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```typescript
import { multiAIService } from '../services/multiAIService';

// åŸºæœ¬AIè«‹æ±‚
const response = await multiAIService.executeRequest(
  'è«‹åˆ†æé€™å¼µå¡ç‰‡çš„æŠ•è³‡åƒ¹å€¼',
  {
    task: 'analysis',
    temperature: 0.3,
    maxTokens: 1000,
  }
);

console.log('AIéŸ¿æ‡‰:', response.data);
console.log('ä½¿ç”¨æ¨¡å‹:', response.metadata.model);
console.log('è™•ç†æ™‚é–“:', response.metadata.processingTime);
console.log('æˆæœ¬:', response.metadata.cost);
```

### 2. æŒ‡å®šAIæä¾›å•†

```typescript
// æŒ‡å®šä½¿ç”¨OpenAIçš„GPT-4
const response = await multiAIService.executeRequest(
  'è«‹è©³ç´°åˆ†æé€™å¼µå¡ç‰‡çš„ç¨€æœ‰åº¦',
  {
    provider: 'openai',
    model: 'gpt-4',
    task: 'analysis',
    temperature: 0.2,
  }
);
```

### 3. ä½¿ç”¨AIæ¨¡å‹ç®¡ç†å™¨

```typescript
import { aiModelManager } from '../services/aiModelManager';

// åŸ·è¡Œå¡ç‰‡è­˜åˆ¥ä»»å‹™
const response = await aiModelManager.executeCardTask(
  'card_recognition',
  'è«‹è­˜åˆ¥é€™å¼µå¡ç‰‡çš„åŸºæœ¬ä¿¡æ¯',
  {
    imageData: 'base64-image-data',
    preferences: {
      prioritizeAccuracy: true,
      requireVision: true,
    },
  }
);
```

## ğŸ“š API åƒè€ƒ

### MultiAIService é¡

#### ä¸»è¦æ–¹æ³•

##### `executeRequest(prompt, config)`

åŸ·è¡Œå–®å€‹AIè«‹æ±‚

**åƒæ•¸:**

- `prompt: string` - AIæç¤ºæ–‡æœ¬
- `config: AIRequestConfig` - è«‹æ±‚é…ç½®

**è¿”å›:** `Promise<AIResponse>`

**é…ç½®é¸é …:**

```typescript
interface AIRequestConfig {
  provider?: AIProvider; // æŒ‡å®šAIæä¾›å•†
  model?: AIModelType; // æŒ‡å®šæ¨¡å‹
  task: AITaskType; // ä»»å‹™é¡å‹
  temperature?: number; // å‰µé€ æ€§ (0-2)
  maxTokens?: number; // æœ€å¤§è¼¸å‡ºtokenæ•¸
  topP?: number; // æ ¸æ¡æ¨£åƒæ•¸
  frequencyPenalty?: number; // é »ç‡æ‡²ç½°
  presencePenalty?: number; // å­˜åœ¨æ‡²ç½°
  timeout?: number; // è¶…æ™‚æ™‚é–“
  retryAttempts?: number; // é‡è©¦æ¬¡æ•¸
  fallbackProviders?: AIProvider[]; // å‚™ç”¨æä¾›å•†
}
```

##### `executeBatchRequests(requests)`

æ‰¹é‡åŸ·è¡ŒAIè«‹æ±‚

**åƒæ•¸:**

- `requests: Array<{prompt: string, config: AIRequestConfig}>`

**è¿”å›:** `Promise<BatchAIResponse>`

##### `getProviderStatus()`

ç²å–æ‰€æœ‰æä¾›å•†ç‹€æ…‹

**è¿”å›:** `Array<ProviderStatus>`

##### `getUsageStats()`

ç²å–ä½¿ç”¨çµ±è¨ˆ

**è¿”å›:** `Promise<UsageStats>`

##### `testProviderConnection(provider)`

æ¸¬è©¦æä¾›å•†é€£æ¥

**åƒæ•¸:**

- `provider: AIProvider`

**è¿”å›:** `Promise<boolean>`

### AIModelManager é¡

#### ä¸»è¦æ–¹æ³•

##### `executeCardTask(taskType, prompt, options)`

åŸ·è¡Œå¡ç‰‡ç›¸é—œAIä»»å‹™

**åƒæ•¸:**

- `taskType: string` - ä»»å‹™é¡å‹
- `prompt: string` - æç¤ºæ–‡æœ¬
- `options?: CardTaskOptions` - ä»»å‹™é¸é …

**æ”¯æŒçš„ä»»å‹™é¡å‹:**

- `card_recognition` - å¡ç‰‡è­˜åˆ¥
- `condition_analysis` - æ¢ä»¶åˆ†æ
- `authenticity_check` - çœŸå½é©—è­‰
- `price_prediction` - åƒ¹æ ¼é æ¸¬
- `market_analysis` - å¸‚å ´åˆ†æ
- `investment_advice` - æŠ•è³‡å»ºè­°

##### `selectBestModelForTask(taskType, preferences)`

ç‚ºä»»å‹™é¸æ“‡æœ€ä½³æ¨¡å‹

**åƒæ•¸:**

- `taskType: string` - ä»»å‹™é¡å‹
- `preferences?: ModelPreferences` - æ¨¡å‹åå¥½

**åå¥½é¸é …:**

```typescript
interface ModelPreferences {
  prioritizeSpeed?: boolean; // å„ªå…ˆé€Ÿåº¦
  prioritizeAccuracy?: boolean; // å„ªå…ˆæº–ç¢ºæ€§
  prioritizeCost?: boolean; // å„ªå…ˆæˆæœ¬
  requireVision?: boolean; // éœ€è¦è¦–è¦ºèƒ½åŠ›
  maxCost?: 'low' | 'medium' | 'high'; // æœ€å¤§æˆæœ¬
}
```

##### `compareModels(models)`

æ¯”è¼ƒå¤šå€‹æ¨¡å‹

**åƒæ•¸:**

- `models: AIModelType[]` - è¦æ¯”è¼ƒçš„æ¨¡å‹åˆ—è¡¨

**è¿”å›:** `Array<ModelComparison>`

##### `getRecommendedModels(useCase)`

ç²å–æ¨è–¦æ¨¡å‹

**åƒæ•¸:**

- `useCase: string` - ä½¿ç”¨å ´æ™¯

**æ”¯æŒçš„å ´æ™¯:**

- `card-scanning` - å¡ç‰‡æƒæ
- `price-analysis` - åƒ¹æ ¼åˆ†æ
- `market-research` - å¸‚å ´ç ”ç©¶
- `investment-advice` - æŠ•è³‡å»ºè­°
- `cost-effective` - æˆæœ¬æ•ˆç›Š
- `high-accuracy` - é«˜æº–ç¢ºæ€§
- `fast-processing` - å¿«é€Ÿè™•ç†

## ğŸ¨ ä½¿ç”¨å ´æ™¯

### 1. å¡ç‰‡æƒæå’Œè­˜åˆ¥

```typescript
// ä½¿ç”¨è¦–è¦ºæ¨¡å‹é€²è¡Œå¡ç‰‡è­˜åˆ¥
const recognitionResult = await aiModelManager.executeCardTask(
  'card_recognition',
  'è«‹è­˜åˆ¥é€™å¼µå¡ç‰‡çš„åç¨±ã€ç³»åˆ—ã€ç¨€æœ‰åº¦ç­‰ä¿¡æ¯',
  {
    imageData: base64ImageData,
    preferences: {
      prioritizeAccuracy: true,
      requireVision: true,
    },
  }
);
```

### 2. æ¢ä»¶åˆ†æå’Œè©•ç´š

```typescript
// åˆ†æå¡ç‰‡ç‹€æ³
const conditionResult = await aiModelManager.executeCardTask(
  'condition_analysis',
  'è«‹è©³ç´°åˆ†æé€™å¼µå¡ç‰‡çš„ç‹€æ³ï¼ŒåŒ…æ‹¬ç£¨æç¨‹åº¦ã€é‚Šç·£ç‹€æ³ç­‰',
  {
    imageData: base64ImageData,
    preferences: {
      prioritizeAccuracy: true,
      requireVision: true,
    },
  }
);
```

### 3. åƒ¹æ ¼é æ¸¬å’Œå¸‚å ´åˆ†æ

```typescript
// é æ¸¬åƒ¹æ ¼è¶¨å‹¢
const predictionResult = await aiModelManager.executeCardTask(
  'price_prediction',
  `åŸºæ–¼ä»¥ä¸‹æ•¸æ“šé æ¸¬åƒ¹æ ¼è¶¨å‹¢ï¼š
  - ç•¶å‰åƒ¹æ ¼: $500
  - æ­·å²æœ€é«˜: $800
  - äº¤æ˜“é‡: 150å¼µ/æœˆ
  - éœ€æ±‚è¶¨å‹¢: ä¸Šå‡`,
  {
    preferences: {
      prioritizeAccuracy: true,
      maxCost: 'medium',
    },
  }
);
```

### 4. æ‰¹é‡è™•ç†

```typescript
// æ‰¹é‡åˆ†æå¤šå¼µå¡ç‰‡
const batchRequests = [
  {
    prompt: 'åˆ†æå¡ç‰‡Açš„æŠ•è³‡åƒ¹å€¼',
    config: { task: 'analysis', temperature: 0.3 },
  },
  {
    prompt: 'é æ¸¬å¡ç‰‡Bçš„åƒ¹æ ¼è¶¨å‹¢',
    config: { task: 'prediction', temperature: 0.2 },
  },
  {
    prompt: 'ç”Ÿæˆå¡ç‰‡Cçš„æ”¶è—å»ºè­°',
    config: { task: 'generation', temperature: 0.7 },
  },
];

const batchResult = await multiAIService.executeBatchRequests(batchRequests);
```

### 5. æˆæœ¬å„ªåŒ–

```typescript
// ä½¿ç”¨æˆæœ¬å„ªåŒ–çš„è² è¼‰å¹³è¡¡
multiAIService.updateConfig({
  loadBalancing: 'cost-optimized',
});

// æˆ–è€…æŒ‡å®šä½æˆæœ¬æ¨¡å‹
const response = await multiAIService.executeRequest('ç°¡å–®çš„æ–‡æœ¬åˆ†æ', {
  task: 'analysis',
  preferences: {
    prioritizeCost: true,
    maxCost: 'low',
  },
});
```

## âš™ï¸ é…ç½®ç®¡ç†

### 1. æ›´æ–°æœå‹™é…ç½®

```typescript
// æ›´æ–°è² è¼‰å¹³è¡¡ç­–ç•¥
multiAIService.updateConfig({
  loadBalancing: 'performance-optimized',
  caching: {
    enabled: true,
    ttl: 600000, // 10åˆ†é˜
    maxSize: 2000,
  },
});
```

### 2. æ·»åŠ è‡ªå®šç¾©æä¾›å•†

```typescript
const customProvider = {
  provider: 'custom' as AIProvider,
  apiKey: 'your-api-key',
  endpoint: 'https://your-api-endpoint.com',
  models: ['custom-model'] as AIModelType[],
  capabilities: ['analysis', 'generation'] as AITaskType[],
  rateLimit: {
    requestsPerMinute: 30,
    requestsPerHour: 1800,
    tokensPerMinute: 50000,
  },
  cost: {
    inputTokensPerDollar: 40000,
    outputTokensPerDollar: 80000,
  },
  priority: 5,
  isActive: true,
};

multiAIService.addProvider(customProvider);
```

### 3. æ·»åŠ è‡ªå®šç¾©æ¨¡å‹

```typescript
const customModel = {
  model: 'custom-advanced' as AIModelType,
  provider: 'custom',
  capabilities: {
    vision: true,
    code: true,
    math: true,
    reasoning: true,
    creativity: true,
    analysis: true,
    multilingual: true,
    contextLength: 16384,
    maxTokens: 8192,
  },
  performance: {
    speed: 'fast',
    accuracy: 'high',
    cost: 'low',
  },
  specializations: ['domain-specific', 'custom-analysis'],
};

aiModelManager.addCustomModel(customModel);
```

## ğŸ“Š ç›£æ§å’Œåˆ†æ

### 1. ç²å–ä½¿ç”¨çµ±è¨ˆ

```typescript
const stats = await multiAIService.getUsageStats();
console.log('ç¸½è«‹æ±‚æ•¸:', stats.totalRequests);
console.log('ç¸½æˆæœ¬:', stats.totalCost);
console.log('å¹³å‡è™•ç†æ™‚é–“:', stats.averageProcessingTime);
console.log('æä¾›å•†åˆ†æ:', stats.providerBreakdown);
```

### 2. æª¢æŸ¥æä¾›å•†ç‹€æ…‹

```typescript
const status = multiAIService.getProviderStatus();
status.forEach((provider) => {
  console.log(`${provider.provider}:`, {
    isActive: provider.isActive,
    capabilities: provider.capabilities,
    rateLimit: provider.rateLimit,
    priority: provider.priority,
  });
});
```

### 3. æ¸¬è©¦é€£æ¥

```typescript
const providers = ['openai', 'claude', 'gemini', 'azure'];
for (const provider of providers) {
  const isConnected = await multiAIService.testProviderConnection(provider);
  console.log(`${provider}: ${isConnected ? 'âœ… é€£æ¥æ­£å¸¸' : 'âŒ é€£æ¥å¤±æ•—'}`);
}
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. æä¾›å•†é€£æ¥å¤±æ•—

```typescript
// æª¢æŸ¥APIå¯†é‘°æ˜¯å¦æ­£ç¢ºè¨­ç½®
console.log(
  'OpenAI API Key:',
  process.env.EXPO_PUBLIC_OPENAI_API_KEY ? 'å·²è¨­ç½®' : 'æœªè¨­ç½®'
);

// æ¸¬è©¦é€£æ¥
const isConnected = await multiAIService.testProviderConnection('openai');
if (!isConnected) {
  console.log('OpenAIé€£æ¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥APIå¯†é‘°å’Œç¶²çµ¡é€£æ¥');
}
```

#### 2. æ¨¡å‹ä¸æ”¯æŒç‰¹å®šä»»å‹™

```typescript
// æª¢æŸ¥æ¨¡å‹èƒ½åŠ›
const modelCapability = aiModelManager.getModelCapability('gpt-3.5-turbo');
if (!modelCapability?.capabilities.vision) {
  console.log('GPT-3.5-turboä¸æ”¯æŒè¦–è¦ºä»»å‹™ï¼Œè«‹ä½¿ç”¨GPT-4æˆ–Gemini Vision');
}
```

#### 3. æˆæœ¬è¶…æ¨™

```typescript
// è¨­ç½®æˆæœ¬é™åˆ¶
const response = await multiAIService.executeRequest('åˆ†æä»»å‹™', {
  task: 'analysis',
  preferences: {
    prioritizeCost: true,
    maxCost: 'low',
  },
});
```

#### 4. è™•ç†è¶…æ™‚

```typescript
// è¨­ç½®è¶…æ™‚å’Œé‡è©¦
const response = await multiAIService.executeRequest('è¤‡é›œåˆ†æä»»å‹™', {
  task: 'analysis',
  timeout: 30000, // 30ç§’è¶…æ™‚
  retryAttempts: 3,
  fallbackProviders: ['claude', 'gemini'],
});
```

## ğŸš€ æ€§èƒ½å„ªåŒ–

### 1. ç·©å­˜ç­–ç•¥

```typescript
// å•Ÿç”¨ç·©å­˜
multiAIService.updateConfig({
  caching: {
    enabled: true,
    ttl: 300000, // 5åˆ†é˜
    maxSize: 1000,
  },
});
```

### 2. è² è¼‰å¹³è¡¡å„ªåŒ–

```typescript
// æ ¹æ“šéœ€æ±‚é¸æ“‡è² è¼‰å¹³è¡¡ç­–ç•¥
const strategies = {
  priority: 'å„ªå…ˆç´šç­–ç•¥ - æŒ‰é…ç½®çš„å„ªå…ˆç´šé¸æ“‡',
  'cost-optimized': 'æˆæœ¬å„ªåŒ– - é¸æ“‡æˆæœ¬æœ€ä½çš„æä¾›å•†',
  'performance-optimized': 'æ€§èƒ½å„ªåŒ– - é¸æ“‡è™•ç†é€Ÿåº¦æœ€å¿«çš„',
  'round-robin': 'è¼ªè©¢ç­–ç•¥ - è¼ªæµä½¿ç”¨æ‰€æœ‰æä¾›å•†',
};

// è¨­ç½®ç‚ºæˆæœ¬å„ªåŒ–
multiAIService.updateConfig({
  loadBalancing: 'cost-optimized',
});
```

### 3. æ‰¹é‡è™•ç†å„ªåŒ–

```typescript
// å°‡å¤šå€‹è«‹æ±‚åˆä½µç‚ºæ‰¹é‡è«‹æ±‚ä»¥æé«˜æ•ˆç‡
const batchRequests = cards.map((card) => ({
  prompt: `åˆ†æå¡ç‰‡: ${card.name}`,
  config: { task: 'analysis' },
}));

const results = await multiAIService.executeBatchRequests(batchRequests);
```

## ğŸ”’ å®‰å…¨è€ƒæ…®

### 1. APIå¯†é‘°ç®¡ç†

```typescript
// ä½¿ç”¨ç’°å¢ƒè®Šé‡ç®¡ç†APIå¯†é‘°
const config = {
  openai: process.env.EXPO_PUBLIC_OPENAI_API_KEY,
  claude: process.env.EXPO_PUBLIC_ANTHROPIC_API_KEY,
  gemini: process.env.EXPO_PUBLIC_GOOGLE_GEMINI_API_KEY,
};
```

### 2. è«‹æ±‚é©—è­‰

```typescript
// é©—è­‰è¼¸å…¥æ•¸æ“š
const validationResult = validateInput(
  z.object({
    prompt: z.string().min(1).max(10000),
    task: z.enum(['analysis', 'prediction', 'generation']),
  }),
  { prompt, task }
);

if (!validationResult.isValid) {
  throw new Error(validationResult.errorMessage);
}
```

### 3. éŒ¯èª¤è™•ç†

```typescript
try {
  const response = await multiAIService.executeRequest(prompt, config);
  return response;
} catch (error) {
  logger.error('AIè«‹æ±‚å¤±æ•—:', error);
  // å¯¦ç¾é©ç•¶çš„éŒ¯èª¤è™•ç†é‚è¼¯
  throw new Error('AIæœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œé‡è©¦');
}
```

## ğŸ“ˆ æœ€ä½³å¯¦è¸

### 1. æ¨¡å‹é¸æ“‡ç­–ç•¥

- **è¦–è¦ºä»»å‹™**: å„ªå…ˆä½¿ç”¨ Gemini Vision æˆ– GPT-4
- **åˆ†æä»»å‹™**: ä½¿ç”¨ Claude-3 æˆ– GPT-4
- **æˆæœ¬æ•æ„Ÿ**: ä½¿ç”¨ Gemini Pro æˆ– GPT-3.5-turbo
- **é«˜æº–ç¢ºæ€§**: ä½¿ç”¨ GPT-4 æˆ– Claude-3

### 2. æç¤ºå·¥ç¨‹

```typescript
// å¥½çš„æç¤ºç¤ºä¾‹
const goodPrompt = `
è«‹åˆ†æé€™å¼µå¯¶å¯å¤¢å¡ç‰‡çš„æŠ•è³‡åƒ¹å€¼ï¼š

å¡ç‰‡ä¿¡æ¯ï¼š
- åç¨±: çš®å¡ä¸˜
- ç³»åˆ—: åŸºç¤ç³»åˆ—
- ç¨€æœ‰åº¦: ç¨€æœ‰
- ç•¶å‰åƒ¹æ ¼: $50

è«‹å¾ä»¥ä¸‹è§’åº¦åˆ†æï¼š
1. å¸‚å ´éœ€æ±‚è¶¨å‹¢
2. ä¾›æ‡‰é‡åˆ†æ
3. æŠ•è³‡é¢¨éšªè©•ä¼°
4. åƒ¹æ ¼é æ¸¬
5. æŠ•è³‡å»ºè­°
`;

// é¿å…éæ–¼ç°¡çŸ­çš„æç¤º
const badPrompt = 'åˆ†æé€™å¼µå¡ç‰‡'; // å¤ªç°¡çŸ­ï¼Œç¼ºä¹ä¸Šä¸‹æ–‡
```

### 3. éŒ¯èª¤è™•ç†ç­–ç•¥

```typescript
// å¯¦ç¾å¥å£¯çš„éŒ¯èª¤è™•ç†
async function robustAIRequest(prompt: string, config: AIRequestConfig) {
  try {
    return await multiAIService.executeRequest(prompt, config);
  } catch (error) {
    // å˜—è©¦å‚™ç”¨æä¾›å•†
    if (config.fallbackProviders && config.fallbackProviders.length > 0) {
      for (const fallback of config.fallbackProviders) {
        try {
          const fallbackConfig = { ...config, provider: fallback };
          return await multiAIService.executeRequest(prompt, fallbackConfig);
        } catch (fallbackError) {
          logger.warn(`å‚™ç”¨æä¾›å•† ${fallback} ä¹Ÿå¤±æ•—:`, fallbackError);
          continue;
        }
      }
    }

    // æ‰€æœ‰æä¾›å•†éƒ½å¤±æ•—ï¼Œæ‹‹å‡ºéŒ¯èª¤
    throw new Error('æ‰€æœ‰AIæä¾›å•†éƒ½ä¸å¯ç”¨');
  }
}
```

## ğŸ”„ æ›´æ–°æ—¥èªŒ

### v1.0.0 (2024-01-XX)

- âœ… åˆå§‹ç‰ˆæœ¬ç™¼å¸ƒ
- âœ… æ”¯æŒ OpenAIã€Claudeã€Gemini ç­‰ä¸»æµæä¾›å•†
- âœ… å¯¦ç¾æ™ºèƒ½æ¨¡å‹é¸æ“‡å’Œè² è¼‰å¹³è¡¡
- âœ… æ·»åŠ æ‰¹é‡è™•ç†åŠŸèƒ½
- âœ… å¯¦ç¾æˆæœ¬å„ªåŒ–å’Œç›£æ§

### è¨ˆåŠƒåŠŸèƒ½

- ğŸ”„ æ”¯æŒæ›´å¤šAIæä¾›å•†
- ğŸ”„ å¯¦ç¾æ›´æ™ºèƒ½çš„æ¨¡å‹é¸æ“‡ç®—æ³•
- ğŸ”„ æ·»åŠ A/Bæ¸¬è©¦åŠŸèƒ½
- ğŸ”„ å¯¦ç¾æ›´è©³ç´°çš„æ€§èƒ½åˆ†æ
- ğŸ”„ æ”¯æŒæ¨¡å‹å¾®èª¿å’Œè‡ªå®šç¾©è¨“ç·´

## ğŸ¤ è²¢ç»

æ­¡è¿è²¢ç»ä»£ç¢¼ã€å ±å‘Šå•é¡Œæˆ–æå‡ºæ”¹é€²å»ºè­°ï¼

## ğŸ“„ æˆæ¬Š

æœ¬é …ç›®æ¡ç”¨ MIT æˆæ¬Šæ¢æ¬¾ã€‚
