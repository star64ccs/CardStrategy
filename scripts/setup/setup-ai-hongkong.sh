#!/bin/bash

# ğŸ‡­ğŸ‡° é¦™æ¸¯ç”¨æˆ¶ AI æœå‹™è¨­ç½®è…³æœ¬
# å°ˆç‚ºé¦™æ¸¯ç”¨æˆ¶è¨­è¨ˆçš„ AI æœå‹™é…ç½®è…³æœ¬

set -e

# é¡è‰²å®šç¾©
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥èªŒå‡½æ•¸
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æª¢æŸ¥ç³»çµ±
check_system() {
    log_info "æª¢æŸ¥ç³»çµ±ç’°å¢ƒ..."
    
    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        OS="linux"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        OS="macos"
    elif [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "cygwin" ]]; then
        OS="windows"
    else
        log_error "ä¸æ”¯æ´çš„æ“ä½œç³»çµ±: $OSTYPE"
        exit 1
    fi
    
    log_success "æª¢æ¸¬åˆ°æ“ä½œç³»çµ±: $OS"
}

# æª¢æŸ¥å¿…è¦å·¥å…·
check_requirements() {
    log_info "æª¢æŸ¥å¿…è¦å·¥å…·..."
    
    # æª¢æŸ¥ curl
    if ! command -v curl &> /dev/null; then
        log_error "curl æœªå®‰è£ï¼Œè«‹å…ˆå®‰è£ curl"
        exit 1
    fi
    
    # æª¢æŸ¥ git
    if ! command -v git &> /dev/null; then
        log_error "git æœªå®‰è£ï¼Œè«‹å…ˆå®‰è£ git"
        exit 1
    fi
    
    # æª¢æŸ¥ Node.js
    if ! command -v node &> /dev/null; then
        log_error "Node.js æœªå®‰è£ï¼Œè«‹å…ˆå®‰è£ Node.js"
        exit 1
    fi
    
    log_success "æ‰€æœ‰å¿…è¦å·¥å…·å·²å®‰è£"
}

# å‰µå»ºç’°å¢ƒè®Šé‡æ–‡ä»¶
create_env_files() {
    log_info "å‰µå»ºç’°å¢ƒè®Šé‡æ–‡ä»¶..."
    
    # å‰µå»º .env æ–‡ä»¶
    if [ ! -f ".env" ]; then
        cat > .env << EOF
# ==================== AI æœå‹™é…ç½® (é¦™æ¸¯ç”¨æˆ¶å°ˆç”¨) ====================

# Hugging Face (æ¨è–¦ - å®Œå…¨å…è²»)
HUGGING_FACE_API_KEY=your_huggingface_token_here

# Cohere (å…è²»é¡åº¦ - 5 requests/minute)
COHERE_API_KEY=your_cohere_api_key_here

# Replicate (å…è²»é¡åº¦ - 500 requests/month)
REPLICATE_API_KEY=your_replicate_token_here

# æœ¬åœ° AI æœå‹™
OLLAMA_API_URL=http://localhost:11434/api/generate
LM_STUDER_API_URL=http://localhost:1234/v1/chat/completions

# å‚™ç”¨ OpenAI/Gemini (å¦‚æœä½¿ç”¨ VPN)
OPENAI_API_KEY=your_openai_api_key_here
GOOGLE_PALM_API_KEY=your_gemini_api_key_here

# ==================== å…¶ä»–é…ç½® ====================
NODE_ENV=development
EOF
        log_success "å‰µå»º .env æ–‡ä»¶"
    else
        log_warning ".env æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³éå‰µå»º"
    fi
    
    # å‰µå»º backend/.env æ–‡ä»¶
    if [ ! -f "backend/.env" ]; then
        cat > backend/.env << EOF
# ==================== å¾Œç«¯ AI æœå‹™é…ç½® ====================

# AI æœå‹™é…ç½®
HUGGING_FACE_API_KEY=your_huggingface_token_here
COHERE_API_KEY=your_cohere_api_key_here
REPLICATE_API_KEY=your_replicate_token_here

# æœ¬åœ° AI é…ç½®
OLLAMA_API_URL=http://localhost:11434/api/generate
LM_STUDER_API_URL=http://localhost:1234/v1/chat/completions

# å‚™ç”¨é…ç½®
OPENAI_API_KEY=your_openai_api_key_here
GOOGLE_PALM_API_KEY=your_gemini_api_key_here

# æ•¸æ“šåº«é…ç½®
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=cardstrategy_dev
POSTGRES_USER=cardstrategy_user
POSTGRES_PASSWORD=your_secure_password

# JWT é…ç½®
JWT_SECRET=your_jwt_secret_here
JWT_EXPIRE=24h

# å…¶ä»–é…ç½®
NODE_ENV=development
PORT=3000
LOG_LEVEL=info
EOF
        log_success "å‰µå»º backend/.env æ–‡ä»¶"
    else
        log_warning "backend/.env æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³éå‰µå»º"
    fi
}

# å®‰è£ Ollama (æœ¬åœ° AI æ¨¡å‹)
install_ollama() {
    log_info "å®‰è£ Ollama (æœ¬åœ° AI æ¨¡å‹)..."
    
    if command -v ollama &> /dev/null; then
        log_success "Ollama å·²å®‰è£"
        return
    fi
    
    case $OS in
        "macos")
            log_info "åœ¨ macOS ä¸Šå®‰è£ Ollama..."
            if command -v brew &> /dev/null; then
                brew install ollama
            else
                log_error "è«‹å…ˆå®‰è£ Homebrew: https://brew.sh/"
                exit 1
            fi
            ;;
        "linux")
            log_info "åœ¨ Linux ä¸Šå®‰è£ Ollama..."
            curl -fsSL https://ollama.ai/install.sh | sh
            ;;
        "windows")
            log_warning "è«‹æ‰‹å‹•ä¸‹è¼‰ä¸¦å®‰è£ Ollama: https://ollama.ai/download"
            log_info "ä¸‹è¼‰å¾Œè«‹é‹è¡Œ: ollama serve"
            return
            ;;
    esac
    
    log_success "Ollama å®‰è£å®Œæˆ"
}

# ä¸‹è¼‰ Ollama æ¨¡å‹
download_ollama_models() {
    log_info "ä¸‹è¼‰ Ollama æ¨¡å‹..."
    
    if ! command -v ollama &> /dev/null; then
        log_warning "Ollama æœªå®‰è£ï¼Œè·³éæ¨¡å‹ä¸‹è¼‰"
        return
    fi
    
    # å•Ÿå‹• Ollama æœå‹™
    if ! pgrep -x "ollama" > /dev/null; then
        log_info "å•Ÿå‹• Ollama æœå‹™..."
        ollama serve &
        sleep 5
    fi
    
    # ä¸‹è¼‰å¸¸ç”¨æ¨¡å‹
    models=("llama2" "codellama" "mistral")
    
    for model in "${models[@]}"; do
        log_info "ä¸‹è¼‰æ¨¡å‹: $model"
        ollama pull $model || log_warning "ä¸‹è¼‰æ¨¡å‹ $model å¤±æ•—"
    done
    
    log_success "æ¨¡å‹ä¸‹è¼‰å®Œæˆ"
}

# æ¸¬è©¦ AI æœå‹™
test_ai_services() {
    log_info "æ¸¬è©¦ AI æœå‹™é€£æ¥..."
    
    # æ¸¬è©¦ Hugging Face
    if [ -n "$HUGGING_FACE_API_KEY" ] && [ "$HUGGING_FACE_API_KEY" != "your_huggingface_token_here" ]; then
        log_info "æ¸¬è©¦ Hugging Face API..."
        response=$(curl -s -X POST https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium \
            -H "Authorization: Bearer $HUGGING_FACE_API_KEY" \
            -H "Content-Type: application/json" \
            -d '{"inputs": "Hello"}' || echo "FAILED")
        
        if [[ $response != *"FAILED"* ]]; then
            log_success "Hugging Face API é€£æ¥æˆåŠŸ"
        else
            log_warning "Hugging Face API é€£æ¥å¤±æ•—"
        fi
    fi
    
    # æ¸¬è©¦ Ollama
    if command -v ollama &> /dev/null; then
        log_info "æ¸¬è©¦ Ollama æœå‹™..."
        if pgrep -x "ollama" > /dev/null; then
            response=$(curl -s -X POST http://localhost:11434/api/generate \
                -H "Content-Type: application/json" \
                -d '{"model": "llama2", "prompt": "Hello", "stream": false}' || echo "FAILED")
            
            if [[ $response != *"FAILED"* ]]; then
                log_success "Ollama æœå‹™é€£æ¥æˆåŠŸ"
            else
                log_warning "Ollama æœå‹™é€£æ¥å¤±æ•—"
            fi
        else
            log_warning "Ollama æœå‹™æœªé‹è¡Œ"
        fi
    fi
}

# é¡¯ç¤ºè¨­ç½®æŒ‡å—
show_setup_guide() {
    log_info "é¡¯ç¤ºè¨­ç½®æŒ‡å—..."
    
    cat << EOF

${GREEN}ğŸ‰ AI æœå‹™è¨­ç½®å®Œæˆï¼${NC}

${BLUE}ğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œï¼š${NC}

1. ${YELLOW}é…ç½® API å¯†é‘°ï¼š${NC}
   - è¨ªå• https://huggingface.co/ è¨»å†Šä¸¦ç²å– API Token
   - è¨ªå• https://cohere.ai/ è¨»å†Šä¸¦ç²å– API Key
   - è¨ªå• https://replicate.com/ è¨»å†Šä¸¦ç²å– API Token

2. ${YELLOW}æ›´æ–°ç’°å¢ƒè®Šé‡ï¼š${NC}
   - ç·¨è¼¯ .env æ–‡ä»¶
   - å°‡ "your_xxx_here" æ›¿æ›ç‚ºå¯¦éš›çš„ API å¯†é‘°

3. ${YELLOW}å•Ÿå‹• Ollama (å¯é¸)ï¼š${NC}
   - é‹è¡Œ: ollama serve
   - ä¸‹è¼‰æ¨¡å‹: ollama pull llama2

4. ${YELLOW}æ¸¬è©¦æœå‹™ï¼š${NC}
   - é‹è¡Œ: npm run test:ai
   - æˆ–æ‰‹å‹•æ¸¬è©¦å„å€‹ API

${BLUE}ğŸ“š è©³ç´°æ–‡æª”ï¼š${NC}
- é¦™æ¸¯ç”¨æˆ¶ AI è¨­ç½®æŒ‡å—: docs/HONG_KONG_AI_SETUP_GUIDE.md
- å°ˆæ¡ˆæ–‡æª”: docs/

${BLUE}ğŸ”§ æ•…éšœæ’é™¤ï¼š${NC}
- å¦‚æœé‡åˆ°å•é¡Œï¼Œè«‹æŸ¥çœ‹ docs/HONG_KONG_AI_SETUP_GUIDE.md
- æˆ–è¯ç¹«é–‹ç™¼åœ˜éšŠ

${GREEN}ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼ğŸ‡­ğŸ‡°${NC}

EOF
}

# ä¸»å‡½æ•¸
main() {
    echo -e "${BLUE}"
    echo "ğŸ‡­ğŸ‡° CardStrategy AI æœå‹™è¨­ç½®è…³æœ¬ (é¦™æ¸¯ç”¨æˆ¶å°ˆç”¨)"
    echo "================================================"
    echo -e "${NC}"
    
    check_system
    check_requirements
    create_env_files
    install_ollama
    download_ollama_models
    test_ai_services
    show_setup_guide
    
    log_success "è¨­ç½®å®Œæˆï¼"
}

# é‹è¡Œä¸»å‡½æ•¸
main "$@"
